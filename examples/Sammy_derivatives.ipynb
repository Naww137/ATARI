{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ATARI.theory.resonance_statistics import make_res_par_avg\n",
    "from ATARI.theory.scattering_params import FofE_recursive\n",
    "import ATARI.utils.hdf5 as h5io\n",
    "from matplotlib.pyplot import *\n",
    "import numpy as np\n",
    "from scipy.linalg import svdvals\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import os\n",
    "from copy import copy\n",
    "from ATARI.sammy_interface import sammy_classes, sammy_functions, template_creator\n",
    "from ATARI.sammy_interface.sammy_deriv import get_derivatives, find_interpolation_array, interpolate_derivatives\n",
    "\n",
    "from ATARI.ModelData.particle import Particle, Neutron\n",
    "from ATARI.ModelData.particle_pair import Particle_Pair\n",
    "from ATARI.ModelData.experimental_model import Experimental_Model\n",
    "\n",
    "from ATARI.Bayes.bayes_update import Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sammypath = ''\n",
    "assert(sammypath != '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATARI Sammy Interface\n",
    "\n",
    "This user example details basic use of the ATARI/SAMMY interface module. \n",
    "The example given here shows how to do individual sammy runs using the NV or IQ solution scheme.\n",
    "The AutoFit example will detail sammy interface with YW scheme that can be used for automatic evaluations or simultaneous data fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### setup the reaction model and sample a resonance\n",
    "Ta181 = Particle(Z=73, A=181, I=3.5, mass=180.94803, name='Ta181')\n",
    "Ta_pair = Particle_Pair(isotope = \"Ta181\",\n",
    "                        resonance_ladder = pd.DataFrame(),\n",
    "                        formalism = \"XCT\",\n",
    "                        energy_range = [175,225],\n",
    "                        ac = 0.8127,\n",
    "                        target=Ta181,\n",
    "                        projectile=Neutron,\n",
    "                        l_max = 1)\n",
    "Ta_pair.add_spin_group(Jpi='3.0',\n",
    "                       J_ID=1,\n",
    "                       D=9.0030,\n",
    "                       gn2_avg=452.56615,\n",
    "                       gn2_dof=1,\n",
    "                       gg2_avg=32.0,\n",
    "                       gg2_dof=1000)\n",
    "Ta_pair.resonance_ladder = pd.DataFrame({'E':[197.0, 203.0], 'Gg':[64.0, 65.0], 'Gn1':[22.7266399211, 32.0], 'J_ID':[1.0, 1.0], 'Jpi':[3.0, 3.0], 'L':[0, 0]})\n",
    "Ta_pair.expand_ladder()\n",
    "Ta_pair.resonance_ladder[[\"varyE\", \"varyGg\", \"varyGn1\"]] = 1\n",
    "# Ta_pair.resonance_ladder[[\"varyE\", \"varyGg\", \"varyGn1\"]] = 0\n",
    "# Ta_pair.resonance_ladder[[\"varyGn1\"]] = 1\n",
    "# Ta_pair.resonance_ladder[[\"varyGg\"]] = 1\n",
    "# Ta_pair.resonance_ladder[[\"varyE\"]] = 1\n",
    "\n",
    "# setup experimental transmission model\n",
    "# exp_model_T = Experimental_Model(energy_range=Ta_pair.energy_range, energy_grid=[199,201])\n",
    "exp_model_T = Experimental_Model(energy_range=Ta_pair.energy_range)\n",
    "\n",
    "\n",
    "# calculate experimentally corrected transmission or capture yield with sammy\n",
    "rto = sammy_classes.SammyRunTimeOptions(sammypath,\n",
    "                                        Print             = True,\n",
    "                                        bayes             = True,\n",
    "                                        derivatives       = False,\n",
    "                                        bayes_scheme      = 'NV',\n",
    "                                        iterations        = 1,\n",
    "                                        use_least_squares = True,\n",
    "                                        keep_runDIR       = True,\n",
    "                                        sammy_runDIR      = 'sammy_runDIR_2')\n",
    "\n",
    "template_creator.make_input_template('template_T.inp', Ta_pair, exp_model_T, rto)\n",
    "exp_model_T.template = os.path.realpath('template_T.inp')\n",
    "\n",
    "Ta_pair.resonance_ladder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate syndat from measurement models\n",
    "from ATARI.ModelData.measurement_models.transmission_rpi import Transmission_RPI\n",
    "from ATARI.syndat.control import Syndat_Model, syndatOPT\n",
    "\n",
    "\n",
    "synOPT = syndatOPT(sampleRES=False, calculate_covariance=True, explicit_covariance=True, )\n",
    "\n",
    "synT = Syndat_Model(generative_experimental_model=exp_model_T, options=synOPT)\n",
    "\n",
    "## need to test syndat covariance generation with different tof ordering !!!\n",
    "\n",
    "synT.sample(Ta_pair, \n",
    "            sammyRTO=rto,\n",
    "            num_samples=1)\n",
    "\n",
    "datasample = synT.samples[0]\n",
    "print(datasample.pw_reduced)\n",
    "data = datasample.pw_reduced\n",
    "# data['exp'] = data['true']\n",
    "# data['exp_unc'] = 0.000001\n",
    "# data['exp_unc'] = 0.00001\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Making a simple dataset\n",
    "# data = pd.DataFrame({'tof': ['dunno'], 'E':[200.0], 'true':[0.6], 'exp':[0.6], 'exp_unc':[0.01]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(vars(generative.model_parameters))\n",
    "Ta_pair.resonance_ladder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_par_uncert = 1.0\n",
    "\n",
    "# Altering a bad ladder:\n",
    "res_ladder_bad = copy(Ta_pair.resonance_ladder)\n",
    "\n",
    "# print(data.exp.values)\n",
    "exp_data = pd.DataFrame({'E':data.E, 'exp_trans':data.exp, 'exp_unc':data.exp_unc})\n",
    "sammyINP = sammy_classes.SammyInputData(Ta_pair,\n",
    "                                        res_ladder_bad,\n",
    "                                        os.path.realpath('template_T.inp'),\n",
    "                                        exp_model_T,\n",
    "                                        experimental_data = exp_data,\n",
    "                                        energy_grid = exp_model_T.energy_grid,\n",
    "                                        initial_parameter_uncertainty=init_par_uncert)\n",
    "\n",
    "print('Prior')\n",
    "print(res_ladder_bad[['E', 'Gg', 'Gn1']])\n",
    "print()\n",
    "\n",
    "sammy_out = get_derivatives(sammyINP, rto, find_theo_trans=True, u_or_p='u')\n",
    "derivatives = sammy_out.derivatives\n",
    "par_post, Mp = Bayes(sammy_out, Ta_pair, rto, init_par_uncert)\n",
    "print('Custom Bayes:')\n",
    "print(par_post[['E', 'Gg', 'Gn1']])\n",
    "print()\n",
    "\n",
    "rto_bayes = sammy_classes.SammyRunTimeOptions(rto.path_to_SAMMY_exe,\n",
    "                                              derivatives = False,\n",
    "                                              bayes_scheme = 'NV')\n",
    "sammy_out = sammy_functions.run_sammy(sammyINP, rto)\n",
    "print('SAMMY Bayes:')\n",
    "print(sammy_out.par_post[['E', 'Gg', 'Gn1']])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise RuntimeError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 0\n",
    "Jpi = 3.0\n",
    "gg20 = list(Ta_pair.spin_groups.values())[0]['<gg2>']\n",
    "gn20 = list(Ta_pair.spin_groups.values())[0]['<gn2>']\n",
    "Els = np.linspace(50, 10_000, 100)\n",
    "Ggs = np.array([2*gg20])\n",
    "Gns = np.linspace(100, 800, 5)\n",
    "Ls = np.array([0])\n",
    "Es = np.linspace(-10, 10, 100)\n",
    "points, derivatives = find_interpolation_array(Ta_pair, exp_model_T, rto, Els, Ggs, Gns, Ls, Es, u_or_p='u')\n",
    "\n",
    "interpolate_derivatives(points, derivatives, ...)\n",
    "\n",
    "dP_dE_flat = dP_dE.reshape(num_energies,-1)\n",
    "svs = svdvals(dP_dE_flat)\n",
    "svs = np.sort(svs)[::-1]\n",
    "\n",
    "figure(420)\n",
    "clf()\n",
    "plot(range(len(svs)), abs(svs), '.k')\n",
    "yscale('log')\n",
    "grid()\n",
    "xlabel('Rank', fontsize=16)\n",
    "ylabel('Singular Value', fontsize=16)\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = 0\n",
    "# Jpi = 3.0\n",
    "# gg20 = list(Ta_pair.spin_groups.values())[0]['<gg2>']\n",
    "# # gn20 = list(Ta_pair.spin_groups.values())[0]['<gn2>']\n",
    "# num_energies = 100\n",
    "# Es = np.linspace(1e-5, 10_000, 100)\n",
    "# Gns = np.linspace(100, 800, 5)\n",
    "# dP_dE = np.zeros((num_energies, len(Es), len(Gns), 3))\n",
    "# for i, E0 in enumerate(Es):\n",
    "#     print(f'El = {E0}')\n",
    "#     for j, Gn0 in enumerate(Gns):\n",
    "#         E = np.array([E0])\n",
    "#         EB = (E[0]-10,E[0]+10)\n",
    "#         Ta_pair.energy_range = EB\n",
    "#         exp_model_T.energy_range = EB\n",
    "#         E_grid = np.linspace(*EB, num_energies+2)[1:-1]\n",
    "#         P = FofE_recursive(E, Ta_pair.ac, Ta_pair.M, Ta_pair.m, l)[1][l,:]\n",
    "#         Gg  = 2*gg20 * np.ones((1,))\n",
    "#         Gn  = Gn0 * np.ones((1,))\n",
    "#         gg2 = gg20 * np.ones((1,))\n",
    "#         gn2 = Gn0/(2*P) * np.ones((1,))\n",
    "#         Ta_pair.resonance_ladder = pd.DataFrame([E, Gg, Gn, [1], gg2, gn2, [Jpi], [l]],\n",
    "#                                             index=['E', 'Gg', 'Gn1',  'J_ID', 'gg2', 'gn2', 'Jpi', 'L',]).T\n",
    "#         exp_model_T.energy_grid = E_grid\n",
    "#         sammyINP = sammy_classes.SammyInputData(\n",
    "#             Ta_pair,\n",
    "#             Ta_pair.resonance_ladder,\n",
    "#             os.path.realpath('template_T.inp'),\n",
    "#             exp_model_T,\n",
    "#             energy_grid=exp_model_T.energy_grid\n",
    "#         )\n",
    "#         sammy_out = get_derivatives(sammyINP, rto)\n",
    "#         dP_dE[:,i,j,:] = sammy_out.derivatives\n",
    "\n",
    "# dP_dE_flat = dP_dE.reshape(num_energies,-1)\n",
    "# svs = svdvals(dP_dE_flat)\n",
    "# svs = np.sort(svs)[::-1]\n",
    "\n",
    "# figure(420)\n",
    "# clf()\n",
    "# plot(range(len(svs)), abs(svs), '.k')\n",
    "# yscale('log')\n",
    "# grid()\n",
    "# xlabel('Rank', fontsize=16)\n",
    "# ylabel('Singular Value', fontsize=16)\n",
    "# show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dP_dE_flat = dP_dE.reshape(num_energies,-1)\n",
    "svs = svdvals(dP_dE_flat)\n",
    "svs = np.sort(svs)[::-1]\n",
    "\n",
    "figure(421)\n",
    "clf()\n",
    "plot(range(len(svs)), abs(svs), '.k')\n",
    "yscale('log')\n",
    "grid()\n",
    "xlabel('Rank', fontsize=16)\n",
    "ylabel('Singular Value', fontsize=16)\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = 0\n",
    "# Jpi = 3.0\n",
    "# gg20 = 1.0\n",
    "# gn20 = 1.0\n",
    "# EB = (5,500)\n",
    "# E = np.arange(*EB, 10)\n",
    "# N_res = len(E)\n",
    "\n",
    "# Ta_pair.energy_range = EB\n",
    "# exp_model_T.energy_range = EB\n",
    "\n",
    "# E_grid = np.linspace(*EB, 10_000)\n",
    "# P = FofE_recursive(E, Ta_pair.ac, Ta_pair.M, Ta_pair.m, l)[1][l,:]\n",
    "# Gg = 2*gg20 * np.ones((N_res,))\n",
    "# Gn = 2*P*gn20 * np.ones((N_res,))\n",
    "# gg2 = gg20 * np.ones((N_res,))\n",
    "# gn2 = gn20 * np.ones((N_res,))\n",
    "# Ta_pair.resonance_ladder = pd.DataFrame([E, Gg, Gn, [1]*N_res, gg2, gn2, [Jpi]*N_res, [l]*N_res],\n",
    "#                                      index=['E', 'Gg', 'Gn1',  'J_ID', 'gg2', 'gn2', 'Jpi', 'L',]).T\n",
    "# exp_model_T.energy_grid = E_grid\n",
    "# sammyINP = sammy_classes.SammyInputData(\n",
    "#     Ta_pair,\n",
    "#     Ta_pair.resonance_ladder,\n",
    "#     os.path.realpath('template_T.inp'),\n",
    "#     exp_model_T,\n",
    "#     energy_grid=exp_model_T.energy_grid\n",
    "# )\n",
    "# sammy_out = get_derivatives(sammyINP, rto)\n",
    "# print(sammy_out.derivatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise RuntimeError('STOP!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Option to read in idc or you can just pass to sammy a filepath\n",
    "\n",
    "\n",
    "# def read_idc(filepath):\n",
    "#     data = {\n",
    "#         'J': {},\n",
    "#         'C': None,\n",
    "#         'stat': None\n",
    "#     }\n",
    "\n",
    "#     with open(filepath, 'r') as f:\n",
    "#         num_params = None\n",
    "#         in_partial_derivatives = False\n",
    "#         in_uncertainties = False\n",
    "#         in_correlations = False\n",
    "#         for line in f.readlines():\n",
    "            \n",
    "#             if line.lower().startswith(\"nu\"):\n",
    "#                 num_params = int(line.split()[-1])\n",
    "            \n",
    "#             elif line.lower().startswith(\"free-forma\"):\n",
    "#                 in_partial_derivatives = True\n",
    "\n",
    "#             elif line.lower().startswith(\"uncertaint\"):\n",
    "#                 in_partial_derivatives = False\n",
    "#                 in_uncertainties = True\n",
    "            \n",
    "#             elif line.lower().startswith(\"correlatio\"):\n",
    "#                 in_uncertainties = False\n",
    "#                 in_correlations = True\n",
    "\n",
    "#             elif in_partial_derivatives:\n",
    "#                 splitline = line.split()\n",
    "#                 E = float(splitline[0])\n",
    "#                 stat_unc = float(splitline[1])\n",
    "#                 derivatives = [float(x) for x in splitline[2:]]\n",
    "#                 data['J'][E] = {'stat_unc': stat_unc, 'derivatives': derivatives}\n",
    "                \n",
    "#             elif in_uncertainties:\n",
    "#                 uncertainties = [float(e) for e in line.split()]\n",
    "#                 data['C'] = np.diag(uncertainties)\n",
    "\n",
    "#             elif in_correlations:\n",
    "#                 assert isinstance(num_params, int)\n",
    "#                 correlations = []\n",
    "#                 for _ in range(num_params):\n",
    "#                     line = f.readline().strip().split()\n",
    "#                     correlations.append([float(x) for x in line])\n",
    "\n",
    "#     data['stat'] = None  # You need to fill in the logic for reading the 'stat' data\n",
    "\n",
    "#     return data\n",
    "\n",
    "# Usage\n",
    "# filepath = '/Users/noahwalton/research_local/resonance_fitting/ATARI_workspace/measurement_data/trans-Ta-1mm.idc'\n",
    "# read_data = read_idc(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datasample.covariance_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasample.covariance_data['CovT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### decomposed covariance test\n",
    "# stat = copy(datasample.covariance_data[\"diag_stat\"])\n",
    "# CT = copy(datasample.covariance_data['CovT'])\n",
    "# J = copy(datasample.covariance_data['Jac_sys'])\n",
    "# C = copy(datasample.covariance_data['Cov_sys'])\n",
    "# # C = np.diag(np.diag(C))\n",
    "# test = J.T@C@J\n",
    "# test.index.name = None\n",
    "# assert(np.max(abs((np.diag(stat.var_stat) + test) - CT)) == 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the data with sammy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rto.bayes=True\n",
    "rto.get_ECSCM = True\n",
    "rto.ECSCM_rxn = 'transmission'\n",
    "\n",
    "sammyINP = sammy_classes.SammyInputData(\n",
    "    Ta_pair,\n",
    "    Ta_pair.resonance_ladder,\n",
    "    os.path.realpath('template_T.inp'),\n",
    "    exp_model_T,\n",
    "    # energy_grid=exp_model_T.energy_grid\n",
    "    experimental_data=data,\n",
    "    experimental_covariance = datasample.covariance_data\n",
    ")\n",
    "\n",
    "sammyINP.initial_parameter_uncertainty=10\n",
    "\n",
    "# std = 0.01\n",
    "# data.exp = np.random.default_rng().normal(data.true, std)\n",
    "# data.exp_unc = std\n",
    "\n",
    "sammyINP.experimental_data = data\n",
    "sammyINP.resonance_ladder[\"varyE\"] = np.ones(len(Ta_pair.resonance_ladder))\n",
    "sammyINP.resonance_ladder[\"varyGg\"] = np.ones(len(Ta_pair.resonance_ladder))\n",
    "sammyINP.resonance_ladder[\"varyGn1\"] = np.ones(len(Ta_pair.resonance_ladder))\n",
    "\n",
    "sammyOUT2 = sammy_functions.run_sammy(sammyINP, rto)\n",
    "print(sammyOUT2.chi2_post)\n",
    "print(sammyOUT2.chi2n_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BACKGround functions\n",
    "EXPON 0 0 582.77685 33.822441 0.0514968 0.0046811 \n",
    "\n",
    "NORMALIZATION AND BACKGROUND ARE NEXT\n",
    "1.0000000        0.0                                         3\n",
    "0.0384200\n",
    "\n",
    "!! when fitting background or normalization, the output lst has an additional column I need to be robust to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Plot \n",
    "figure()\n",
    "\n",
    "errorbar(data.E, data.exp, yerr=data.exp_unc, zorder=0,\n",
    "                                        fmt='.', color='k', linewidth=0.5, markersize=1.5, capsize=1, label='12mm')\n",
    "\n",
    "plot(data.E, data.true, 'g')\n",
    "\n",
    "plot(sammyOUT2.pw.E, sammyOUT2.pw.theo_trans, 'b')\n",
    "plot(sammyOUT2.pw_post.E, sammyOUT2.pw_post.theo_trans_bayes, 'r')\n",
    "\n",
    "# plot(sammyOUT2.pw.E, sammyOUT2.pw.theo_xs, 'b')\n",
    "# plot(sammyOUT2.pw_post.E, sammyOUT2.pw_post.theo_xs_bayes, 'r')\n",
    "# # plot(sammyOUT_old.est_df.E, sammyOUT_old.est_df.theo, 'b')\n",
    "# # sammyOUT_old = copy(sammyOUT2)\n",
    "\n",
    "x = sammyOUT2.est_df.E\n",
    "y = sammyOUT2.est_df.theo\n",
    "y_err=  sammyOUT2.est_df.theo_unc #\n",
    "# y_err = np.sqrt(np.diag(sammyOUT2.ECSCM))\n",
    "fill_between(x, y - y_err, y + y_err, color='r', alpha=0.5, label='Error Band')\n",
    "plot(x, y, 'r')\n",
    "\n",
    "ylabel(\"T\")\n",
    "\n",
    "# xlim([200,225])\n",
    "# ylim([-0.1,1.1])\n",
    "legend()\n",
    "\n",
    "xlabel('Energy (eV)')\n",
    "tight_layout()\n",
    "\n",
    "\n",
    "# figure()\n",
    "# imshow(sammyOUT2.ECSCM)\n",
    "# colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ladder = copy(sammyOUT2.par_post)\n",
    "print(ladder)\n",
    "Ta_pair.spin_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ATARI.utils.atario import expand_sammy_ladder_2_atari\n",
    "\n",
    "expand_sammy_ladder_2_atari(Ta_pair, ladder)\n",
    "ladder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples = 100\n",
    "\n",
    "# cov_true = np.zeros([len(sammyOUT2.pw),len(sammyOUT2.pw)])\n",
    "# cov_est = np.zeros([len(sammyOUT2.est_df),len(sammyOUT2.est_df)])\n",
    "\n",
    "# for i in range(samples):\n",
    "#     # synT.run(sammyOUT.pw)\n",
    "#     data.exp = np.random.default_rng().normal(synT.data.true, std)\n",
    "#     data.exp_unc = std\n",
    "#     sammyINP.experimental_data = synT.data\n",
    "#     sammyOUT2 = sammy_functions.run_sammy(sammyINP, rto)\n",
    "#     residual = np.atleast_2d(sammyOUT2.pw.theo_trans_bayes) - np.atleast_2d(synT.data.true)\n",
    "#     cov_true += residual.T@residual\n",
    "#     cov_est += sammyOUT2.ECSCM\n",
    "#     # true.append(cov_true)\n",
    "#     # est.append(cov_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iest = 0\n",
    "# fig, axes = subplots(1,2, figsize=(10,4))\n",
    "# # im1 = axes[0].imshow(np.log10(cov_true/(samples)))\n",
    "# # im2 = axes[1].imshow(np.log10(cov_est/(samples-1)))\n",
    "# im1 = axes[0].pcolormesh(cov_true/(samples), clim=(-1e-5, 8e-5))\n",
    "# im2 = axes[1].pcolormesh(cov_est/(samples-1), clim=(-1e-5, 8e-5))\n",
    "# axes[0].set_title(\"empirical\")\n",
    "\n",
    "# axes[1].set_title(\"estimated\")\n",
    "# # for ax in axes:\n",
    "# colorbar(im1)\n",
    "\n",
    "# colorbar(im2)\n",
    "\n",
    "# print(\"Empirical Fnorm\")\n",
    "# print(np.linalg.norm(cov_true/(samples), ord='fro'))\n",
    "# print(\"Estimated Fnorm\")\n",
    "# print(np.linalg.norm(cov_est/(samples-1), ord='fro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Plot \n",
    "# figure()\n",
    "\n",
    "# # errorbar(synT.data.E, synT.data.exp, yerr=synT.data.exp_unc, zorder=0,\n",
    "# #                                         fmt='.', color='k', linewidth=0.5, markersize=1.5, capsize=1, label='12mm')\n",
    "\n",
    "# # plot(synT.data.E, synT.data.true, 'g')\n",
    "# plot(synT.data.E, np.sqrt(np.diag(cov_true/samples)), label=\"empirical\")\n",
    "# plot(x, np.sqrt(np.diag(cov_est/(samples-1))), label=\"mean estimated\")\n",
    "\n",
    "\n",
    "# xlim([200,225])\n",
    "# # ylim([-0.1,1.1])\n",
    "# legend()\n",
    "\n",
    "# xlabel('Energy (eV)')\n",
    "# tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # result_dict = {}\n",
    "# # stds = [0.1, 0.01, 0.001, 0.0001]\n",
    "# stds = [0.00001, 0.05]\n",
    "\n",
    "# for istd in stds:\n",
    "#     samples = 1000\n",
    "#     cov_true = np.zeros([len(sammyOUT2.pw), len(sammyOUT2.pw)])\n",
    "#     cov_est = np.zeros([len(sammyOUT2.est_df), len(sammyOUT2.est_df)])\n",
    "#     for i in range(samples):\n",
    "#         # synT.run(sammyOUT.pw)\n",
    "#         synT.data.exp = np.random.default_rng().normal(synT.data.true, istd)\n",
    "#         synT.data.exp_unc = istd\n",
    "#         sammyINP.experimental_data = synT.data\n",
    "#         sammyOUT2 = sammy_functions.run_sammy(sammyINP, rto)\n",
    "#         residual = np.atleast_2d(\n",
    "#             sammyOUT2.pw.theo_trans_bayes) - np.atleast_2d(synT.data.true)\n",
    "#         cov_true += residual.T@residual\n",
    "#         cov_est += sammyOUT2.ECSCM\n",
    "        \n",
    "#     result_dict[istd] = [cov_true, cov_est]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stds = [1.0, 0.1, 0.05, 0.01, 0.001, 0.0001]\n",
    "# true= []\n",
    "# est = []\n",
    "\n",
    "# for istd in stds:\n",
    "#     res = result_dict[istd]\n",
    "#     cov_true = res[0]\n",
    "#     cov_est = res[1]\n",
    "#     print(istd)\n",
    "#     # print(\"Empirical Fnorm: \", np.linalg.norm(cov_true/(samples), ord='fro'))\n",
    "#     # print(\"Estimated Fnorm: \", np.linalg.norm(cov_est/(samples-1), ord='fro'))\n",
    "#     # true.append(np.linalg.norm(cov_true/(samples), ord='fro'))\n",
    "#     # est.append(np.linalg.norm(cov_est/(samples-1), ord='fro'))\n",
    "#     print(\"Empirical Fnorm: \", np.sum(np.diag(cov_true)**2/(samples)))\n",
    "#     print(\"Estimated Fnorm: \", np.sum(np.diag(cov_est)**2/(samples-1)))\n",
    "#     true.append(np.sum(np.diag(cov_true)**2/(samples)))\n",
    "#     est.append(np.sum(np.diag(cov_est)**2/(samples-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure()\n",
    "# plot(stds, true, '.', label='Empirical')\n",
    "# plot(stds, est, '.r', label='Estimate')\n",
    "# xscale(\"log\")\n",
    "# yscale(\"log\")\n",
    "# legend()\n",
    "# # ylabel(\"Noise Level\")\n",
    "# xlabel(\"Noise Level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
